# Global configuration
status = error
name = CustomSparkLogConfig

# ========== Appenders ==========

# Console appender (used for system and app logs)
appender.console.type = Console
appender.console.name = CONSOLE
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} [%t] %-5level %logger{36} - %msg%n

# File appender (used only for your app logs)
appender.file.type = File
appender.file.name = FILE
appender.file.fileName = logs/app-logs.log
appender.file.layout.type = PatternLayout
appender.file.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} [%t] %-5level %logger{36} - %msg%n

# ========== Loggers ==========

# Your application logs: INFO and up, sent to both console and file
logger.SparkPlayground.name = SparkPlayground
logger.SparkPlayground.level = info
logger.SparkPlayground.additivity = false
logger.SparkPlayground.appenderRefs = console, file
logger.SparkPlayground.appenderRef.console.ref = CONSOLE
logger.SparkPlayground.appenderRef.file.ref = FILE

# All system/infrastructure logs: ERROR only to console
logger.system.name = org.apache
logger.system.level = error
logger.system.additivity = false
logger.system.appenderRefs = console
logger.system.appenderRef.console.ref = CONSOLE

logger.hadoop.name = org.apache.hadoop
logger.hadoop.level = error
logger.hadoop.additivity = false
logger.hadoop.appenderRefs = console
logger.hadoop.appenderRef.console.ref = CONSOLE

logger.spark.name = org.apache.spark
logger.spark.level = error
logger.spark.additivity = false
logger.spark.appenderRefs = console
logger.spark.appenderRef.console.ref = CONSOLE

# ========== Root Logger ==========

# Default to ERROR for everything else
rootLogger.level = error
rootLogger.appenderRefs = console
rootLogger.appenderRef.console.ref = CONSOLE
